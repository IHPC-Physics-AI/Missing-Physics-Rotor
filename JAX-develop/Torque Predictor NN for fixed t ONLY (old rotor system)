import jax
import jax.numpy as jnp
from flax import linen as nn
from flax.training import train_state
import optax
from functools import partial
import matplotlib.pyplot as plt

# Initialize random key
rng = jax.random.PRNGKey(42)

# Constants
I = 4.667e-10  # Moment of inertia (kg·m²)
gamma = 0.118  # Friction coefficient (rad/s)
c = I * gamma  # Damping coefficient (N·m·s)
epsilon = 8.854e-12  # Permittivity (F/m)
A = 2e-6  # Effective overlap area between electrodes and rotor arms (m²)
V0 = 600  # Peak voltage (V)
R = 0.005  # Radius of rotor (m)
d0 = 0.001  # Baseline distance (m)

# Rotor arms and electrode angles
arm_angles = jnp.array([0, jnp.pi / 2, jnp.pi, (3 * jnp.pi) / 2])
electrode_angles = jnp.linspace(0, 2 * jnp.pi, 6, endpoint=False)

# Precomputed constants
R2 = 2 * R
d0_squared = d0**2
epsilon_A = epsilon * A
R_epsilon_A = epsilon_A * R

# Precompute triangular waveforms on a time grid
time_grid = jnp.linspace(0, 1, 1000)
V1_table = V0 * (2 * jnp.abs(2 * (time_grid % 1) - 1) - 1)
V2_table = jnp.roll(V1_table, jnp.floor(len(time_grid) / 3).astype(int))
V3_table = jnp.roll(V1_table, jnp.floor(2 * len(time_grid) / 3).astype(int))

@jax.jit
def electrode_voltages_precomputed(t, f):
    idx = jnp.floor((f * t) % 1 * len(time_grid)).astype(int)
    v1 = V1_table[idx]
    v2 = V2_table[idx]
    v3 = V3_table[idx]
    return jnp.array([v1, v2, v3, v1, v2, v3])

# Torque computation function
def compute_torques_scalar(theta, t, f):
    angle_diff = theta + arm_angles[:, jnp.newaxis] - electrode_angles[jnp.newaxis, :]
    sin_half_angle_diff = jnp.sin(angle_diff / 2)
    distances_squared = d0_squared + (R2 * sin_half_angle_diff)**2
    voltages_squared = electrode_voltages_precomputed(t, f)**2
    # Reshape voltages_squared to (1, 6) for broadcasting
    voltages_squared_reshaped = voltages_squared.reshape(1, 6)
    torques = (R_epsilon_A * voltages_squared_reshaped / distances_squared) * jnp.sign(jnp.sin(angle_diff))
    return jnp.sum(torques)

# Scale torque function
def scale_torque(torque):
    # Use mean and std for scaling
    mean = jnp.mean(torque)
    std = jnp.std(torque)
    scaled = (torque - mean) / std
    return scaled, (mean, std)

# Unscale torque function
def unscale_torque(torque_scaled, scale_params):
    mean, std = scale_params
    return torque_scaled * std + mean

# Generate training data for multiple frequencies
num_theta_points = 1000
frequencies = jnp.arange(0.5, 8.5, 0.5)  # Frequencies from 0.5 Hz to 8.0 Hz

theta_train_vals = jnp.linspace(0, 2 * jnp.pi, num_theta_points)

# Create meshgrid of theta and frequency
theta_grid, f_grid = jnp.meshgrid(theta_train_vals, frequencies, indexing='ij')

# Flatten the grids to create training pairs
theta_train = theta_grid.ravel()
f_train = f_grid.ravel()

# Compute torque for each (theta, frequency) pair
torque_train = jax.vmap(compute_torques_scalar, in_axes=(0, None, 0))(theta_train, 20.0, f_train)

# Scale the torque
torque_train_scaled, scale_params = scale_torque(torque_train)

# Combine theta and frequency into a single input array
X_train = jnp.stack([theta_train, f_train], axis=-1)
y_train_scaled = torque_train_scaled.reshape(-1, 1)


# Enhanced Model Architecture
class TorquePredictor(nn.Module):
    @nn.compact
    def __call__(self, x):
        # x should have two features: theta and frequency
        # Rich periodic encoding with frequency
        theta, frequency = x[:, 0:1], x[:, 1:2]  # Separate theta and frequency
        x = jnp.concatenate([
            theta,
            frequency,
            # jnp.sin(theta), jnp.cos(theta),
            # jnp.sin(2 * theta), jnp.cos(2 * theta),
            # jnp.sin(3 * theta), jnp.cos(3 * theta),
            # jnp.sin(4 * theta), jnp.cos(4 * theta)
        ], axis=-1)

        # Larger network with residual connections
        x = nn.Dense(256)(x)
        x = jnp.sin(2*jnp.pi*x) # + jnp.cos(2*jnp.pi*x)
        # x = nn.swish(x)
        x = nn.Dense(128)(x)
        x = nn.swish(x)
        x = nn.Dense(64)(x)
        x = nn.swish(x)
        return nn.Dense(1)(x)

# Initialize model
model = TorquePredictor()
params = model.init(rng, jnp.ones((1, 2)))  # Input size is now (theta, frequency)

# Robust Training Setup
optimizer = optax.chain(
    optax.clip(1.0),
    optax.adam(learning_rate=1e-4)
)
state = train_state.TrainState.create(
    apply_fn=model.apply,
    params=params,
    tx=optimizer
)

# Training loop
loss_history = []  # Initialize loss_history list

@jax.jit
def train_step(state, batch):
    X_batch, y_batch_scaled = batch
    def loss_fn(params):
        pred_scaled = state.apply_fn(params, X_batch)
        # add ODE solver for EoM
        # outcome -> solution of x_pred
        # compute MSE for x_pred vs. x_truth
        return jnp.mean((pred_scaled - y_batch_scaled) ** 2)
    loss, grads = jax.value_and_grad(loss_fn)(state.params)
    return state.apply_gradients(grads=grads), loss

for epoch in range(3000):
    state, loss = train_step(state, (X_train, y_train_scaled))
    loss_history.append(loss.item()) # Append loss to the list
    if epoch % 100 == 0:
        print(f"Epoch {epoch}, Loss: {loss:.4f}")

# Plotting the training loss history
plt.figure(figsize=(10, 5))
plt.plot(loss_history, label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training Loss History')
plt.legend()
plt.grid(True)
plt.show()

# Evaluation
theta_test_vals = jnp.linspace(0, 2 * jnp.pi, 100)
frequencies_test = jnp.arange(0.5, 8.5, 0.5)

plt.figure(figsize=(12, 6))

for f in frequencies_test:
    # Create test data for the current frequency
    theta_test = theta_test_vals.reshape(-1, 1)
    frequency_test = jnp.full_like(theta_test, f)
    X_test = jnp.concatenate([theta_test, frequency_test], axis=-1)


    # Compute true torque for the current frequency
    torque_true = jax.vmap(compute_torques_scalar, in_axes=(0, None, None))(theta_test.squeeze(), 20.0, f)

    # Predict and unscale
    torque_pred_scaled = model.apply(state.params, X_test)
    torque_pred = unscale_torque(torque_pred_scaled, scale_params)

    # Plotting true vs predicted
    plt.plot(theta_test, torque_true, label=f'True Torque (f={f}Hz)', linewidth=2)
    plt.plot(theta_test, torque_pred.squeeze(), '--', label=f'Predicted Torque (f={f}Hz)', linewidth=2)


plt.xlabel('Theta (radians)')
plt.ylabel('Torque (Original Scale)')
plt.title('True Torque')
plt.legend()
plt.grid(True)
plt.show()

# Metrics - Note: Calculating a single MSE and Max Error across all frequencies might not be representative.
# Consider calculating metrics per frequency or a weighted average if needed.
# For simplicity, we'll calculate across all points plotted.
# Flatten true and predicted torques from the last plotted frequency for metric calculation
mse = jnp.mean((torque_true - torque_pred.squeeze())**2)
print(f"Test MSE (last frequency plotted): {mse:.3e}")
print(f"Max Error (last frequency plotted): {jnp.max(jnp.abs(torque_true - torque_pred.squeeze())):.3e}")
